# transform
# Transformer Model on Wikitext-103 Dataset

This repository implements a Transformer model for language modeling on the **Wikitext-103** dataset. It is designed for full reproducibility, with clear instructions for setup, training, evaluation, and result visualization.

---

## ğŸ“ Project Structure
transform/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run.sh                 # One-click script to run training & evaluation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ wikitext-103-raw-v1/   # Raw text data (downloaded separately)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ accuracy_loss_comparison.png     
â”‚   â”œâ”€â”€ loss_comparison.png           
â”‚   â””â”€â”€ loss_separate_comparison.png 
â”œâ”€â”€ train.py                   # Training script
â”œâ”€â”€ test.py                    # Evaluation script
â”œâ”€â”€ model.py                   # Transformer model definition
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ LICENSE

---

## âš™ï¸ Environment Setup

### 1. Clone the repository
```bash
git clone https://github.com/abc1234299/transform.git
cd transform

### 2. Create virtual environment and install dependencies
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– Windows:
# venv\Scripts\activate

pip install --upgrade pip
pip install -r requirements.txt

### Hardware Requirements
GPU: è‡³å°‘ 12 GB æ˜¾å­˜ï¼ˆæ¨è RTX 3060 / 3090 / A100ï¼‰
CUDA: æ”¯æŒ CUDA 11.8 æˆ–æ›´é«˜ç‰ˆæœ¬
å†…å­˜ (RAM): â‰¥ 16 GB
ç£ç›˜ç©ºé—´: â‰¥ 500 MBï¼ˆä¸å«æ•°æ®é›†ï¼‰

#è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
export PYTHONHASHSEED=0
export CUBLAS_WORKSPACE_CONFIG=:4096:8

### train
python train.py \
    --data_dir data/wikitext-103-raw-v1 \
    --batch_size 64 \
    --lr 0.001 \
    --epochs 20 \
    --model_dim 512 \
    --n_layers 6 \
    --n_heads 8 \
    --dropout 0.1 \
    --seed 42 \
    --save_dir results/checkpoints \
    --log_interval 100

### test
python test.py \
    --data_dir data/wikitext-103-raw-v1 \
    --checkpoint results/checkpoints/best_model.pth \
    --batch_size 64 \
    --seed 42
    
### ä½¿ç”¨æä¾›çš„è„šæœ¬ä¸€é”®å®Œæˆè®­ç»ƒä¸æµ‹è¯•ï¼š
bash scripts/run.sh

## âš™ï¸ Dataset ä¸‹è½½è¯´æ˜
æœ¬é¡¹ç›®ä½¿ç”¨ Wikitext-103 æ•°æ®é›†ã€‚
#è¯·æ‰‹åŠ¨ä¸‹è½½å¹¶è§£å‹ï¼š
wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-raw-v1.zip
unzip wikitext-103-raw-v1.zip -d data/